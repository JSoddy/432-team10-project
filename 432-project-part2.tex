\documentclass{paper}
\usepackage[T1]{fontenc}
\begin{document}

<Intro Par>
\newline\newline

The area of genetic sequencing has been enjoying a period of exponential
growth for several decades now. Breakthroughs in chemistry, as well as 
significant improvements in sequencing equipment, have led to a rapid 
decline in the cost of sequencing an organism's genetic data. At the 
same time, the increasing power of computing machinery and the decreasing
cost of storage have encouraged the ever-greater accumulation of data in 
a large variety of areas. These two pressures have made, and will 
continue to make, the sequencing of DNA from large numbers of organisms 
more accessible. Already, there are projects in various stages of 
completion which aim to sequence hundreds, or even thousands, of genomes 
from a single species or clade. While these developments are beneficial 
to the fields of biology and genomics, they do present new challenges 
and highlight shortcomings in the existing models used to represent 
genetic data. The current standard in genomics is to use the genome of a 
single organism as a reference for its species. The increasing prevalence
of multiple complete genomes per species leads to a desire for more than
one reference sequence per species. Older models in computational 
genomics do not have the power required to adequately handle multiple 
reference genomes. It is now seen as desirable to create a pan-genome, 
a single representation of all available gene sequences from a species, 
which can be viewed as a single entity. The SplitMEM algorithm is 
designed to take multiple genomic lines and convert them to a compressed
de Bruijn graph pan-genome representation, which will enable the 
isolation of common features in the genomes so that characteristics 
of the entire species or clade can be identified while gene sequences 
specific to an individual organism can be de-emphasized.


In most modern networks their is a stable, generally deterministic, data
structure in place to handle requests. By definition, these
deterministic systems are very predictable. Unfortunately, because of their
predictability, they can be abused. Users who understand the nature of 
the network can overload the system with a series of time consuming
requests, which eventually bog down the network. These denial-of-service
(D.O.S.) attacks can occur for a variety of reasons ranging from 
breaching security to gaining an advantage in competitive gaming. In 
general, D.O.S. attacks rely on knowing how the network will respond to 
every request. In theory, if an adversary could not predict a network's 
response, then they could not mount a D.O.S. attack on the network. 
Knowing this, we can proceed in 
creating a data structure that has unpredictable timing 
for any given input, while still performing at a near optimal speed. 
Such a data structure must be able to perform the same operations as 
the original system, while also non-deterministically, i.e. randomly, 
altering itself. This new system should be able to resist all timing-
dependant attacks,
even from attackers who know the algorithm and the previous i/o values used.
In their paper, Darrell Bethea and Michael K. Reiter discuss a data
structure for set operations with these desirable characteristics.

Factoring large  integers is a notoriously hard problem for deterministic 
computing machines. The best method we have now  for factoring is based 
on the probability of a given number being a factor of a larger number. 
Therefore, factoring is a problem which naturally lends itself to a
quantum computer. A quantum computer behaves like a computer with a 
random number generator integrated into each basic computing circuit.
This new aspect enables the computer to perform tasks which involve 
specific uncertainty in every step of computation much more easily.
There are some defining differences involved in quantum computation
which need novel design of the computing system. Referring to quantum
physics, we know that a particle can be in 
different positions at the same time with different probabilities. 
However, the total probabilities of being in all positions sum up to 1. 
Because of this, a quantum state representing some possible outputs
should have the sum of possibilities of being in all positions equal to
1. Thus only a unitary transformation is allowed in quantum computation.
This guarantees total probabilities equal to 1. Although there are no
real quantum computers at this point, it is useful to consider algorithms
to run on it, partly because they may be built in the future, but also
because those algorithms may be modeled on current computing machines.
Peter Shor proposed an algorithm which takes advantage of the properties
of quantum computers to factor prime numbers in time polynomial to the
size of the integer to be factored.


< Closing Par>

\end{document}