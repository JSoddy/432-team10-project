\documentclass[11pt,twocolumn]{article}
\usepackage[margin=1in]{geometry}

\usepackage{amsmath}

%opening
\title{Motivating Data Structures With Unpredictable Timing}
\author{Group 10\\
\small{Tao Huang, Travis Wentz, James Corbett and James Soddy}}

\begin{document}

\maketitle

Protection from malicious attackers is easily understood as a general motivation
for creating data structures with unpredictable timing. More difficult to understand,
however, are the precise ways in which such structures are able to prevent adversaries
from exploiting a system. Our intention is to clearly illustrate, through
high level descriptions and illustrated examples, precisely the way in which attacks
can compromise standard systems, and how the protection offered by randomized
data structures works.

\section{Algorithm}
 At the core of this algorithm is the skip list, which is a specific type of linked list. This algorithm uses a special implementation called circular skip list so that there is truly no beginning nor end to the list. Using this data structure the algorithm chooses an "origin" at random that will serve as the starting point for insertions, deletions, and searches of the lists. A starting origin is chosen at random upon initialization of the circular skip list, then with every subsequent operation a new origin is chosen. The choosing of a new origin also causes a restructuring of the skip lists. The combination of these two factors results in the timing unpredictably of the algorithm. With each call, the adversary itself alters the skip list making any assumptions as to the nature of the lists extremely difficult.
  
\section{Analysis Problems}
These data structures have been analyzed, and details of their suitability and
efficiency have been given in the Bethea/Reiter paper\cite{Bethea09}. However,
making use of this information requires wading through fifteen pages of material such as:

\begin{minipage}{.5\textwidth}

$$\sum_s\sum_{h=1}^\infty\sum_{j=1}^{n_{i+1}} \left( \begin{matrix}
2^{-h}*Pr[S_i=s | I_i]*Pr[S_{i+1}=s' \\ \land dur(inv_{i+1})=d_{i+1}\  
|\  S_i=s \\ \land H_{i+1}=h \land O_{i+1}=v_j] \end{matrix} \right)$$
\hrule
$$\sum_s\sum_{h=1}^\infty\sum_{j=1}^{n_{i+1}} 
\left( \begin{matrix}2^{-h}*Pr[S_i=s | I_i]*
\\Pr[ dur(inv_{i+1})=d_{i+1} \\ \  | \  S_i=s \land H_{i+1}=h \land O_{i+1}=v_j] \end{matrix} \right)$$

\end{minipage}

It is our intention to present the details of the algorithm in such a way that
it is easily understood by anyone with a basic grasp of computing principles,
or even a motivated layperson.


\section{Discussion}

As the paper doesn't provide any comparison of performance of the proposed algorithm, readers may not have an idea about how much improvement introduced by this algorithm over some previous ones. Our first focus is on the performance comparison of the non-circular skip list based algorithm and the circular skip list based algorithm which is the proposed one in the paper. It's natural to compare two algorithms' safety performance which is the central issue in the paper. According to the paper, an adversary's attempts are basically based on probability calculation which may produce some hints at most expensive operations in the system. Using same data structure and invocations, we can simulate enough number of operations on the two algorithms in order to create two time distributions. Safety performance comparison can therefore be easily performed thanks to the fact that distributions can tell how much information revealed over a certain number of operations. For example, if a distribution is close to a uniform one, the adversary does not have a bigger chance to have a  better guess of which invocation is expensive. Along with the performance comparison, we may also perform running time comparison, because weighing pros and cons and finding a balance between them is a central part of any practical implementation of a new technique. Regarding the the above comparisons, we may use Fisher's information formula and running time as numerical summaries of the two most important aspects of algorithms than can be applied in the same scenario. Therefore it's possible to create  a cost function used to balance the pros and cons in catering to customers' demands. 

However, we may further our study of the algorithm by testing it on different data structures to see if serves  consistently well. But the challenging part of this testing would be how to define and choose different data structures as there are infinitely many different data structures. Some tentative structures may be the ones people in this area usually use for testing. Or in the worst case, randomly different data sets  may put on the algorithm to see if their distributions of times are similar. On the other hand, data size of different sizes will be tested to give us an idea of its asymptotic performance. 

If we are luck, we may be able to see some flaws or inconsistency in the algorithm after we run some simulations. Then we can discuss what was going on in the computation and if there's anything different we can do about it.


%\bibliographystyle{plain}
%\bibliography{bibfilename} 

\newpage
\onecolumn
\appendix
\section{Timeline}
<<<<<<< HEAD
=======
(NOTE: it is good form to have a reference to this bibliography somewhere in 
the main body of your paper).

The following are a list of tasks that we need to accomplish in order to 
complete our project:

\begin{enumerate}
\item Outline the final presentation, determine detailed steps and
materials needed to complete our presentation

\item Program the algorithms in comparison and run some simulations.

\item Create the distributions of time to visualize their performances.

\item Run different date sets on the proposed algorithm and visualize the performance.

\item Make videos.

\item Discuss issues seen and possible solutions.

\item Formalize the project.
\end{enumerate}
>>>>>>> origin/master

The following table gives the timeline of how we plan to accomplish these tasks:

\begin{table}[h!]
\centering
\begin{tabular}{ |l | c | r|}
  \hline
  Dates & Who? & Short Description \\
  \hline
  \hline
  
  \hline
  11/07 & All & detailed preplanning \\
  \hline
  11/8-11/15 & All & programming \\
  \hline
  11/16-11/18 & All & run algorithm and collect data \\
  \hline
  11/19 & All & create simulations \\
  \hline
  11/20 & All & discussion of issues \\
  \hline
  11/27 & All & video and more improvement if possible \\
  \hline
  11/28 & All & final touches \\
  \hline
\end{tabular}
\end{table}

\pagebreak

\begin{thebibliography}{9}
	
\bibitem{Bethea09}
	Bethea, Darrell, and Michael K. Reiter,
	\emph{Data Structures with Unpredictable Timing}
	ESORICS,
	2009.
	
\end{thebibliography}

\end{document}
<<<<<<< HEAD


=======
>>>>>>> origin/master
