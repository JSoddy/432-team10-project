\documentclass[11pt,twocolumn]{article}
\usepackage[margin=1in]{geometry}

\usepackage{amsmath}

%opening
\title{Motivating Data Structures With Unpredictable Timing}
\author{Group 10\\
\small{Tao Huang, Travis Wentz, James Corbett and James Soddy}}

\begin{document}

\maketitle

Protection from malicious attackers is easily understood as a general motivation
for creating data structures with unpredictable timing. More difficult to understand,
however, are the precise ways in which such structures are able to prevent adversaries
from exploiting a system. Our intention is to clearly illustrate, through
high level descriptions and visual examples, precisely the way in which attacks
can compromise standard systems and how the protection offered by randomized
data structures works.

\section{Motivation}
What is the problem that this algorithm is trying to solve (note: you may want 
to borrow from your P-2 write-up).

\section{Algorithm}
Brief description of the main points of the algorithm.

\section{Analysis Problems}
These data structures have been analyzed, and details of their suitability and
efficiency have been given in the Bethea/Reiter paper\cite{Bethea09}. However,
making use of this information requires wading through fifteen pages of material such as:

\begin{minipage}{.5\textwidth}

$$\sum_s\sum_{h=1}^\infty\sum_{j=1}^{n_{i+1}} \left( \begin{matrix}
2^{-h}*Pr[S_i=s | I_i]*Pr[S_{i+1}=s' \\ \land dur(inv_{i+1})=d_{i+1}\  
|\  S_i=s \\ \land H_{i+1}=h \land O_{i+1}=v_j] \end{matrix} \right)$$
\hrule
$$\sum_s\sum_{h=1}^\infty\sum_{j=1}^{n_{i+1}} 
\left( \begin{matrix}2^{-h}*Pr[S_i=s | I_i]*
\\Pr[ dur(inv_{i+1})=d_{i+1} \\ \  | \  S_i=s \land H_{i+1}=h \land O_{i+1}=v_j] \end{matrix} \right)$$

\end{minipage}

It is our intention to present the details of the algorithm in such a way that
it is easily understood by anyone with a basic grasp of computing principles,
as well as accessible to a motivated layperson.


\section{Discussion}

As the paper does not provide any comparison of performance of the proposed algorithm, readers may not have an idea of how much this improves upon previous algorithms. Our first focus will be a performance comparison of the non-circular skip list based algorithm to the circular skip list based algorithm which is proposed in the source paper. Comparing the safety performance of the two algorithms is natural as safety performance is the central issue in the source paper. In simple terms, an adversary's attempts to attack a system are based on probability calculation. Discovering patterns may produce some hints at most expensive operations in the system. Using same data structure and invocations, we can simulate a sufficient number of operations on the two algorithms in order to create two time distributions. Safety performance comparison can therefore be easily performed, thanks to the fact that distributions can show how much information is revealed over a certain number of operations. For example, if a distribution is close to uniform, the adversary does not have a better chance at guessing which invocation is expensive. 

Because it is important to find a balance between performance in terms of security and performance in terms of speed, we may also perform run time comparison. In such comparisons, we may use Fisher's information formula and run time as numerical summaries of the two most important aspects of algorithms than can be applied in the same scenario. This may make it possible to create a cost function which can be used to balance speed and security in catering to customers' demands. 

Additionally, we may further our study of the algorithm by testing it on different data structures. The challenging part of this would be choosing suitable data structures, as there are infinitely many data structures. Some tentative structures may be the ones people in this area normally used for testing. Or in the worst case, randomly chosen data sets may put on the algorithm to see if their distribution times are similar. And finally, data of different sizes will be tested to give us an idea of its asymptotic performance. 

It may be that we see some flaws or inconsistencies in the algorithm after we run some simulations. In that case, we can discuss what is going on in the computation and if there is anything different we can do.


\bibliographystyle{plain}
\bibliography{bibfilename} 

\newpage
\onecolumn
\appendix
\section{Timeline}
(NOTE: it is good form to have a reference to this bibliography somewhere in 
the main body of your paper).

The following are a list of tasks that we need to accomplish in order to 
complete our project:

1. Program the algorithms in comparison and run some simulations.

2. Create the distributions of time to visualize their performances.

3. Run different data sets on the proposed algorithm and visualize the performance.

4. Make videos.

5. Discuss issues seen and possible solutions.

6. Formalize the project.

\paragraph{Structure the video.} We need to plan a detailed outline of our 
video.  We will meet together to do this.

\paragraph{Decide materials needed.}  Make sure you have everything you need in 
order to make this 4-5 minute video!

... and so forth.

The following table gives the timeline of how we plan to accomplish these tasks:

\begin{table}[h!]
\centering
\begin{tabular}{ |l | c | r|}
  \hline
  Date & Who? & Short Description \\
  \hline
  \hline
  11/07 & All & programming \\
  \hline
  11/11 & All & simulation \\
  
  \hline
  11/14 & All & performance comparison \\
  
  \hline
  11/16 & All & discussion of issues \\
  
  \hline
  11/21 & All & video and more improvement if possible \\
  
 
  \hline
  11/28 & All & Final fixing \\
  \hline
\end{tabular}
\end{table}

\pagebreak

\begin{thebibliography}{9}
	
\bibitem{Bethea09}
	Bethea, Darrell, and Michael K. Reiter,
	\emph{Data Structures with Unpredictable Timing}
	ESORICS,
	2009.
	
\end{thebibliography}

\end{document}

