\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{algorithm}
\usepackage{algpseudocode}

%opening
\title{CSCI 432, Group Project Part 3}
\author{Group 10}

\begin{document}

\maketitle

%Intro

%Description

In most modern networks their is a stable, generally deterministic, data
structure in place to handle requests. By definition, these
deterministic systems are very predictable. Unfortunately, because of their
predictability, they can be abused. Users who understand the nature of 
the network can overload the system with a series of time consuming
requests, which eventually bog down the network. These denial-of-service
(D.O.S.) attacks can occur for a variety of reasons ranging from 
breaching security to gaining an advantage in competitive gaming. In 
general, D.O.S. attacks rely on knowing how the network will respond to 
every request. In theory, if an adversary could not predict a network's 
response, then they could not mount a D.O.S. attack on the network. 
Knowing this, we are motivated to 
create a data structure that has unpredictable timing 
for any given input, while still performing at a near optimal speed. 
Such a data structure must be able to perform the same operations as 
the original system, while also non-deterministically, i.e. randomly, 
altering itself. This new system should be able to resist all timing-
dependant attacks,
even from attackers who know the algorithm and the previous i/o values used.
In their paper, Darrell Bethea and Michael K. Reiter discuss a data
structure for set operations with these desirable characteristics\cite{Bethea09}.

The problem of creating a data structure with unpredictable timing has been 
attempted previously and in general there are two types of structures.
There are structures who's goal is to make the worst case unpredictable and 
those who's goal is to make the worst case the least detrimental. Both types 
have their limitations and can still be abused by adversary who are smart enough.
A truly timing unpredictable algorithm must seemingly change its internal 
structure often, if not every iteration, so that it can not be learned no 
matter the amount of information an adversary can glean about it. 
To accomplish these goals this algorithm uses a unique implementation of skip 
lists along with a dynamic origin to create a data structure with unpredictable timing.

 At the core of this algorithm are skip lists, which are a specific type of linked list. 
Skip lists are a series of linked lists L0 through Lm, where m is not constant meaning
the number of linked lists can change depending on the input. The base list L0 contains
every value entered into the set and L1 will contain half the values of L0 and so on until 
Lm only contains a single value. What's important about these lists is that for any
list Lk every value on list Lk is also on list Lk-1. This fact along with the lists
being sorted makes traversing through the lists extremely efficient. To traverse the 
lists we start at list Lm and move across our values until the next value is greater 
than our search value. Then we go down a list to list Lm-1 and search that tree starting 
at the value we stopped with on tree Lm. 

	The next step of the algorithm is to take the normal implementation of skip 
lists and alter it slightly. In the initial implementation of skip lists if you
get to the greatest value without having found your search value then it must not 
be in the list. This method assumes that we start at with the smallest value in 
the lists and move until we the largest but this is predictable. This algorithm 
needs to be able to start at any point, or origin, and check all values in the 
lists regardless of if they are larger or smaller. To do this the creators of this 
algorithm made the skip lists circular, meaning that the largest value of the link 
lists points next to the smallest value in the lists. Now when traversing the tree 
we only stop when we have passed the specified origin a second time.
  
	The last critical step to making this algorithm truly timing unpredictable is a 
dynamic origin. Ultimately the goal is to choose to have a new semi randomly chosen 
origin after every function call, loopup(), insert(), or delete(), is made. This would 
make it so no matter how many trials or repetitions of the same values an adversary 
attempted he could never guess where the origin was. In this algorithm this is accomplished 
by adding a few variables to the node class such as "skipped" and "index" which are maintained, 
in a timely fashion, throughout the function calls. First a node is randomly selected from 
all nodes, then using a calculation with the "skipped" and "index" variables from the 
randomly selected node a new origin node is selected. This calculation is quite in depth 
and can go as far as to change the entire height of the tree during when performed. 

%Conclusion

%Algorithm

\begin{algorithm}
\caption{AlgorithmName}
\textbf{Input:} Inputs
\textbf{Output:} Outputs

\begin{algorithmic}[1]
\State $A \gets intarray$
\State $V \gets intarray$
\For{i = 1 to v}
	\For{j = 1 to n}
		\If{D[j] = i}
			\State $A[i-1] \gets 1$
			\State $V[i-1] \gets D[j]$
		\ElsIf{D[j] \textless i}
			\If{A[i-D[j]-1]+1 \textless A[i-1]}
			\State $A[i-1] \gets A[i-D[j]-1]+1$
			\State $V[i-1] \gets D[j]$
			\EndIf
		\EndIf
	\EndFor
\EndFor

\Return A[max]
\end{algorithmic}
\end{algorithm}

\pagebreak

\begin{thebibliography}{9}
	
\bibitem{Bethea09}
	Bethea, Darrell, and Michael K. Reiter,
	\emph{Data Structures with Unpredictable Timing}
	ESORICS,
	2009.
	
\end{thebibliography}

\end{document}

